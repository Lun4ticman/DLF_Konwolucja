{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "  # extend MLP to input 2D\n",
        "# flatten is required -> flatten layer -> reshape or sth\n",
        "# conv2d layer( number_of_kernels, padding, type_of_padding(zeros, ones, average, half(of pixels in kernels), same as the border), stride, ..., input_shape, kernel_size, random_init_kernel (BEWARE OF CLOSE 0))\n",
        "# full forward pass up to 7.11\n",
        "# something like a unit test (PyTorch) and assert\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9bM-cpZ3qEwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change of schedule:\n",
        "  * generative adversarial networks will be rescheduled for a next semester\n",
        "  * autoencoders will not be covered on DLF\n",
        "  * style(?) transfer added to the lecture"
      ],
      "metadata": {
        "id": "9enGjOiG0z3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "  def __init__(self):\n",
        "    self.input = None\n",
        "    self.output = None\n",
        "\n",
        "  def forward(self, input):\n",
        "    raise NotImplementedError('Not done')\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate):\n",
        "    raise NotImplementedError('Not done')"
      ],
      "metadata": {
        "id": "lQGLhsnplR_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation(Layer):\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return self.activation(self.input)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        return np.multiply(output_gradient, self.activation_prime(self.input))"
      ],
      "metadata": {
        "id": "A0HmJ2Ur2g5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU(Activation):\n",
        "  def __init__(self):\n",
        "    def relu(x):\n",
        "      return np.where(x > 0, x, 0)\n",
        "\n",
        "    def relu_prim(x):\n",
        "      return np.where(x > 0, 1, 0)\n",
        "\n",
        "    super().__init__(relu, relu_prim)"
      ],
      "metadata": {
        "id": "rrPbsjqE2oMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid(Activation):\n",
        "  def __init__(self):\n",
        "      def sigmoid(x):\n",
        "          return 1 / (1 + np.exp(-x))\n",
        "\n",
        "      def sigmoid_prim(x):\n",
        "          s = sigmoid(x)\n",
        "          return s * (1 - s)\n",
        "\n",
        "      super().__init__(sigmoid, sigmoid_prim)"
      ],
      "metadata": {
        "id": "lTsWC55zI20M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Test this\n",
        "class TanH(Activation):\n",
        "  def __init__(self):\n",
        "    def tanh(x):\n",
        "      return np.tanh(x)\n",
        "    def tanh_prim(x):\n",
        "      t = tanh(x)\n",
        "      return 1 - t**2\n",
        "\n",
        "    super().__init__(tanh, tanh_prim)"
      ],
      "metadata": {
        "id": "Ivl08JnZGl4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # TODO: Test that\n",
        "# class Softmax(Activation):\n",
        "#   def __init__(self):\n",
        "#     def softmax(x):\n",
        "#       return np.exp(x) / sum(np.exp(x))\n",
        "#     def softmax_prim(y):\n",
        "#       softmax = self.input.reshape(-1, 1)\n",
        "#       d_softmax = softmax - y\n",
        "#       return d_softmax\n",
        "\n",
        "#     super().__init__(softmax, softmax_prim)"
      ],
      "metadata": {
        "id": "KQAw14OLHHGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax(Layer):\n",
        "    def forward(self, input):\n",
        "\n",
        "        self.input = input\n",
        "\n",
        "        max_val = np.max(input, axis=1, keepdims=True) + 1e-10\n",
        "        tmp = np.exp(input - max_val)\n",
        "        self.output = tmp / (np.sum(tmp, axis=1, keepdims=True) + 1e-12)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, d_out, learning_rate):\n",
        "\n",
        "        d_input = np.zeros_like(self.input)\n",
        "\n",
        "        y = self.output\n",
        "        d_input = np.dot(d_out, y)\n",
        "        return d_input\n"
      ],
      "metadata": {
        "id": "iMrm8ZXOpsA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2D:\n",
        "    def __init__(self, image_shape, num_filters, filter_size, stride=(1, 1), padding_type='valid'):\n",
        "\n",
        "        assert stride == (1, 1), 'Other strides not yet implemented'\n",
        "\n",
        "\n",
        "        # image info\n",
        "        self.input_depth, self.input_height, self.input_width = image_shape\n",
        "\n",
        "\n",
        "        # filter info\n",
        "        self.num_filters = num_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.padding_type = padding_type\n",
        "\n",
        "        # kernels\n",
        "        self.kernels = np.random.randn(self.num_filters, self.input_depth, self.filter_size, self.filter_size)\n",
        "\n",
        "        # output\n",
        "        if self.padding_type == 'valid':\n",
        "          self.output = np.zeros((self.num_filters,\n",
        "                                  self.input_depth,\n",
        "                                  self.input_height - self.filter_size + 1,\n",
        "                                  self.input_width - self.filter_size + 1))\n",
        "        else:\n",
        "          self.output = np.zeros((self.num_filters, self.input_depth, self.input_height, self.input_width))\n",
        "\n",
        "        # biases\n",
        "\n",
        "        self.bias = np.random.randn(*self.output.shape)\n",
        "\n",
        "    def convolve2d(self, image, filter, stride, padding_type):\n",
        "\n",
        "        # 28x28 no padding\n",
        "        height, width = image.shape\n",
        "        #filter_height, filter_width = filter.shape\n",
        "\n",
        "        if padding_type == 'valid':\n",
        "\n",
        "          output_height = height - filter.shape[0] + 1\n",
        "          output_width = width - filter.shape[1] + 1\n",
        "        else:\n",
        "          output_height = height\n",
        "          output_width = width\n",
        "\n",
        "        image = self.padding(image, padding_type)\n",
        "\n",
        "        output = np.zeros((output_height, output_width))\n",
        "\n",
        "        for i in range(0, output_height, stride[0]):\n",
        "            for j in range(0, output_width, stride[1]):\n",
        "                output[i][j] = np.sum(image[i:i+filter.shape[0], j:j+filter.shape[1]] * filter)\n",
        "        # 26x26\n",
        "        return output\n",
        "\n",
        "    def padding(self, x, padding_type):\n",
        "      if x.ndim == 2:\n",
        "          if padding_type == 'valid':\n",
        "              return x\n",
        "          elif padding_type == 'same':\n",
        "              pad = (self.filter_size - 1) // 2\n",
        "              return np.pad(x, [(pad, pad), (pad, pad)], 'constant')\n",
        "          elif padding_type == 'full':\n",
        "              pad = self.filter_size - 1\n",
        "              return np.pad(x, [(pad, pad), (pad, pad)], 'constant')\n",
        "      elif x.ndim == 3:\n",
        "          if padding_type == 'valid':\n",
        "              return x\n",
        "          elif padding_type == 'same':\n",
        "              pad = (self.filter_size - 1) // 2\n",
        "              return np.pad(x, [(0, 0), (pad, pad), (pad, pad)], 'constant')\n",
        "          elif padding_type == 'full':\n",
        "              pad = self.filter_size - 1\n",
        "              return np.pad(x, [(0, 0), (pad, pad), (pad, pad)], 'constant')\n",
        "      else:\n",
        "          raise ValueError(\"Input must have either 2 or 3 dimensions\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.input = x\n",
        "\n",
        "        if self.input.ndim == 2:\n",
        "          for i in range(self.num_filters):\n",
        "            for j in range(self.input_depth):\n",
        "              self.output[i][j] += self.convolve2d(self.input, self.kernels[i][j], self.stride, padding_type = self.padding_type)\n",
        "        elif self.input.ndim == 3:\n",
        "          for i in range(self.num_filters):\n",
        "            for j in range(self.input_depth):\n",
        "              self.output[i][j] += self.convolve2d(self.input[j], self.kernels[i][j], self.stride, padding_type = self.padding_type)\n",
        "\n",
        "\n",
        "        # add bias and return\n",
        "        return self.output + self.bias\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        kernels_gradient = np.zeros(self.kernels.shape)\n",
        "        input_gradient = np.zeros(self.input.shape)\n",
        "\n",
        "        if self.input.ndim == 2:\n",
        "          for i in range(self.num_filters):\n",
        "              for j in range(self.input_depth):\n",
        "                 kernels_gradient[i][j] = self.convolve2d(self.input, np.rot90(output_gradient[i][j]), self.stride, 'valid')\n",
        "                 input_gradient += self.convolve2d(output_gradient[i][j], self.kernels[i][j], self.stride, 'full')\n",
        "\n",
        "          self.kernels -= learning_rate * kernels_gradient\n",
        "          self.bias -= learning_rate * output_gradient\n",
        "\n",
        "        elif self.input.ndim == 3:\n",
        "          # if there are different colors\n",
        "          for i in range(self.num_filters):\n",
        "            for j in range(self.input_depth):\n",
        "              kernels_gradient[i][j] = self.convolve2d(self.input[j], np.rot90(output_gradient[i][j]), self.stride, 'valid')\n",
        "              input_gradient[j] += self.convolve2d(output_gradient[i][j], self.kernels[i][j], self.stride, 'full')\n",
        "\n",
        "          self.kernels -= learning_rate * kernels_gradient\n",
        "          self.bias -= learning_rate * output_gradient\n",
        "\n",
        "        return input_gradient"
      ],
      "metadata": {
        "id": "-pFRY8zLaYuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Reshape(Layer):\n",
        "  def __init__(self, input_shape, output_shape):\n",
        "    self.input_shape = input_shape\n",
        "    self.output_shape = output_shape\n",
        "\n",
        "  def forward(self, input):\n",
        "    return np.reshape(input, self.output_shape)\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate):\n",
        "    return np.reshape(output_gradient, self.input_shape)"
      ],
      "metadata": {
        "id": "QNCE4Z7d0-qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense(Layer):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.weights = np.random.randn(output_size, input_size)\n",
        "        self.bias = np.random.randn(output_size, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return np.dot(self.weights, self.input) + self.bias\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        weights_gradient = np.dot(output_gradient, self.input.T)\n",
        "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
        "        self.weights -= learning_rate * weights_gradient\n",
        "        self.bias -= learning_rate * output_gradient\n",
        "        return input_gradient"
      ],
      "metadata": {
        "id": "98075bQJ3Vdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Test in network\n",
        "class Dropout(Layer):\n",
        "  def __init__(self, dropout):\n",
        "    self.dropout = dropout\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.input = input\n",
        "    return self.input\n",
        "\n",
        "  def backward(self, output):\n",
        "    data = np.zeros(output.shape)\n",
        "    value = 1 / self.dropout\n",
        "    data.flat[np.random.choice(len(output.flatten()), int(len(data.flat) * (1 - self.dropout)), replace=False)] = value\n",
        "\n",
        "    self.dropped = np.multiply(output, data)\n",
        "\n",
        "    return self.dropped"
      ],
      "metadata": {
        "id": "heVK5KCFIgL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlV6utUek5Xt"
      },
      "outputs": [],
      "source": [
        "# loss\n",
        "def mse(y_true, y_pred):\n",
        "    return np.average((y_true - y_pred) ** 2)\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "    return 2 * (y_pred - y_true) / np.size(y_true)\n",
        "\n",
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    return np.mean(-y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "def binary_cross_entropy_prime(y_true, y_pred):\n",
        "    return ((1 - y_true) / (1 - y_pred) - y_true / y_pred) / np.size(y_true)\n",
        "\n",
        "\n",
        "def categorical_crossentropy(y_true, y_pred, eps = 1e-10):\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "\n",
        "    return -np.sum(y_true * np.log(y_pred))\n",
        "\n",
        "def categorical_crossentropy_prime(y_true, y_pred, eps = 1e-10):\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "\n",
        "    return -y_true / (y_pred+1e-10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(network, input):\n",
        "    output = input\n",
        "    for layer in network:\n",
        "        output = layer.forward(output)\n",
        "    return output\n",
        "\n",
        "def train(network, loss, loss_prime, x_train, y_train, epochs = 100, learning_rate = 0.01, info = True):\n",
        "    for e in range(epochs):\n",
        "        error = 0\n",
        "        for x, y in zip(x_train, y_train):\n",
        "            # forward\n",
        "            output = predict(network, x)\n",
        "            # error\n",
        "            error += loss(y, output)\n",
        "            #print('error', error.shape)\n",
        "\n",
        "            # backward\n",
        "            grad = loss_prime(y, output)\n",
        "            for layer in reversed(network):\n",
        "                grad = layer.backward(grad, learning_rate)\n",
        "\n",
        "        error /= len(x_train)\n",
        "        if info:\n",
        "            print(f\"{e + 1}/{epochs}, error={error}\")"
      ],
      "metadata": {
        "id": "-CD1Acdr4Tlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils, to_categorical\n",
        "from keras.datasets.mnist import load_data as load_data_MNIST\n",
        "\n",
        "# the data, split between train and test sets\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_data_MNIST() # MNIST\n",
        "# (x_train, y_train), (x_test, y_test) = load_data_Fashion_MNIST() # or Fashion MNIST\n",
        "\n",
        "## flatten the data from 2D to 1D (vector) as the data shape is [28x28]\n",
        "\n",
        "# x_train = x_train.reshape(60000, 784)\n",
        "# x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "## convert to float [0.0 - 1.0]\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape, 'train samples')\n",
        "print(x_test.shape, 'test samples')\n",
        "\n",
        "\n",
        "## One-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "QNxqZOM64U8F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c64925-e1ba-469f-a2a3-6b72c34eda0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) train samples\n",
            "(10000, 28, 28) test samples\n",
            "(60000, 10) (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = x_train[:500], y_train[:500], x_test[:100], y_test[:100]\n",
        "x_train[0].shape, y_train[0].reshape(-1, 1).shape"
      ],
      "metadata": {
        "id": "8XUNh8peYIUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aace42c7-c604-426e-dd86-0bccf9839fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28, 28), (10, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reshape(-1 , 1)"
      ],
      "metadata": {
        "id": "GsO8qTH0IPZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = [\n",
        "    #Convolutional((1, 28, 28), (3, 3), 5, padding = (1,1)),\n",
        "    Conv2D(image_shape = (1, 28, 28), num_filters = 5, filter_size = 3, stride = (1, 1), padding_type = 'same'),\n",
        "    ReLU(),\n",
        "    # no padding, so shape changes\n",
        "    #Reshape (filters, depth, height, width)\n",
        "    Reshape((5, 1, 28, 28), (5 * 1 * 28 * 28, 1)),\n",
        "    Dense(5 * 1 *28 * 28, 100),\n",
        "    ReLU(),\n",
        "    Dense(100, 10),\n",
        "    #ReLU()\n",
        "    Softmax()\n",
        "]"
      ],
      "metadata": {
        "id": "S-SOJ4UHXRd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test forwarda"
      ],
      "metadata": {
        "id": "sA0u5wT_DtnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = np.random.randn(3, 28, 28)"
      ],
      "metadata": {
        "id": "E70-5DxR7JIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(network, x_train[0]).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nQ6kEgY3R4K",
        "outputId": "3c38c55b-45ec-418a-9976-2b8c55c7eda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train(\n",
        "    network,\n",
        "    categorical_crossentropy,\n",
        "    categorical_crossentropy_prime,\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    learning_rate=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "KsU5oc1Y9oDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "y_pred = []\n",
        "y_true = []\n",
        "for x, y in zip(x_test, y_test):\n",
        "    y_pred.append(np.argmax(predict(network, x)))\n",
        "    y_true.append(np.argmax(y))\n",
        "\n",
        "# accuracy score\n",
        "print('Accuracy of the neural network is equal to: ', accuracy_score(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENVkJvSWA3tV",
        "outputId": "f4cacec4-b7d3-4f4c-d38e-d9910cc7cb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the neural network is equal to:  0.08\n"
          ]
        }
      ]
    }
  ]
}
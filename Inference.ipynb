{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) train samples\n",
      "(10000, 784) test samples\n",
      "(500, 10, 1) (100, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from Layers import *\n",
    "from Conv2D import Conv2D, train, predict\n",
    "import pandas as pd\n",
    "\n",
    "# from sklearn.datasets import load_digits\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from Loss_funcs import *\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
    "\n",
    "## flatten the data from 2D to 1D (vector) as the data shape is [28x28]\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "## convert to float [0.0 - 1.0]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')\n",
    "\n",
    "\n",
    "# One-hot encoding\n",
    "# y_train = tensorflow.keras.utils.to_categorical(y_train, 10)\n",
    "# y_test = tensorflow.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "y_train = pd.get_dummies(y_train, dtype=float)\n",
    "y_test = pd.get_dummies(y_test, dtype=float)\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "x_train, y_train, x_test, y_test = x_train[:500], y_train[:500], x_test[:100], y_test[:100]\n",
    "# print(x_train[0].shape, y_train[0].reshape(-1, 1).shape)\n",
    "\n",
    "y_train = np.expand_dims(y_train, axis=-1)\n",
    "y_test = np.expand_dims(y_test, axis =-1)\n",
    "\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m network \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m#Convolutional((1, 28, 28), (3, 3), 5, padding = (1,1)),\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m     \u001B[43mConv2D\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_shape\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_filters\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilter_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_type\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msame\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m,\n\u001B[0;32m      4\u001B[0m     ReLULayer(),\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# no padding, so shape changes\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m#Reshape (filters, depth, height, width)\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# Reshape((5, 1, 28, 28), (5 * 1 * 28 * 28, 1)),\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     FlattenLayer(),\n\u001B[0;32m      9\u001B[0m     Dense(\u001B[38;5;241m5\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m28\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m28\u001B[39m, \u001B[38;5;241m100\u001B[39m),\n\u001B[0;32m     10\u001B[0m     ReLULayer(),\n\u001B[0;32m     11\u001B[0m     Dense(\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m10\u001B[39m),\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m#ReLU()\u001B[39;00m\n\u001B[0;32m     13\u001B[0m     Sigmoid()\n\u001B[0;32m     14\u001B[0m ]\n",
      "File \u001B[1;32m~\\DLF_Konwolucja\\Conv2D.py:13\u001B[0m, in \u001B[0;36mConv2D.__init__\u001B[1;34m(self, image_shape, num_filters, filter_size, stride, padding_type)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m stride \u001B[38;5;241m==\u001B[39m (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOther strides not yet implemented\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# image info\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_depth, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_height, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_width \u001B[38;5;241m=\u001B[39m image_shape\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# filter info\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_filters \u001B[38;5;241m=\u001B[39m num_filters\n",
      "\u001B[1;31mValueError\u001B[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "network = [\n",
    "    #Convolutional((1, 28, 28), (3, 3), 5, padding = (1,1)),\n",
    "    Conv2D(image_shape = (1, 28, 28), num_filters = 5, filter_size = 3, stride = (1, 1), padding_type = 'same'),\n",
    "    ReLULayer(),\n",
    "    # no padding, so shape changes\n",
    "    #Reshape (filters, depth, height, width)\n",
    "    # Reshape((5, 1, 28, 28), (5 * 1 * 28 * 28, 1)),\n",
    "    FlattenLayer(),\n",
    "    Dense(5 * 1 *28 * 28, 100),\n",
    "    ReLULayer(),\n",
    "    Dense(100, 10),\n",
    "    #ReLU()\n",
    "    Sigmoid()\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "network_2 = [\n",
    "    Dense(784, 100),\n",
    "    ReLULayer(),\n",
    "    Dense(100, 10),\n",
    "    Sigmoid()\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from Conv2D import predict, train\n",
    "from Loss_funcs import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (100,100) and (784,) not aligned: 100 (dim 1) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m accuracy_score\n\u001B[1;32m----> 3\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnetwork_2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcategorical_crossentropy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcategorical_crossentropy_prime\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.01\u001B[39;49m\n\u001B[0;32m     11\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DLF_Konwolucja\\Conv2D.py:156\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(network, loss, loss_prime, x_train, y_train, epochs, learning_rate, info)\u001B[0m\n\u001B[0;32m    154\u001B[0m grad \u001B[38;5;241m=\u001B[39m loss_prime(y, output)\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mreversed\u001B[39m(network):\n\u001B[1;32m--> 156\u001B[0m     grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    159\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124m Sample \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(x_train)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, error: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror\u001B[38;5;241m/\u001B[39mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\DLF_Konwolucja\\Layers.py:160\u001B[0m, in \u001B[0;36mDense.backward\u001B[1;34m(self, output_gradient, learning_rate)\u001B[0m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward\u001B[39m(\u001B[38;5;28mself\u001B[39m, output_gradient, learning_rate):\n\u001B[1;32m--> 160\u001B[0m     weights_gradient \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_gradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    161\u001B[0m     input_gradient \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights\u001B[38;5;241m.\u001B[39mT, output_gradient)\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;66;03m# weights_gradient = np.matmul(output_gradient, self.input.T)\u001B[39;00m\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;66;03m# input_gradient = np.matmul(self.weights.T, output_gradient)\u001B[39;00m\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: shapes (100,100) and (784,) not aligned: 100 (dim 1) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train(\n",
    "    network_2,\n",
    "    categorical_crossentropy,\n",
    "    categorical_crossentropy_prime,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    learning_rate=0.01\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\damig\\DLF_Konwolucja\\Layers.py:34: RuntimeWarning: overflow encountered in exp\n",
      "  temp = 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the neural network is equal to:  0.08\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for x, y in zip(x_test, y_test):\n",
    "    y_pred.append(np.argmax(predict(network, x)))\n",
    "    y_true.append(np.argmax(y))\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy of the neural network is equal to: ', accuracy_score(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}